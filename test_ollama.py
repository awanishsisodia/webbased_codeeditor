#!/usr/bin/env python3
"""
Test script to verify Ollama connection and API functionality
"""

import requests
import json
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

def test_ollama_connection():
    """Test basic Ollama connection"""
    print("üß™ Testing Ollama Connection...")
    
    ollama_url = os.getenv('OLLAMA_API_URL', 'http://localhost:11434')
    model = os.getenv('OLLAMA_MODEL', 'llama3')
    
    print(f"üì° Ollama URL: {ollama_url}")
    print(f"ü§ñ Model: {model}")
    
    try:
        # Test basic connection
        response = requests.get(f"{ollama_url}/api/tags", timeout=10)
        if response.status_code == 200:
            print("‚úì Ollama service is accessible")
            
            # Check available models
            models = response.json()
            if 'models' in models:
                available_models = [m['name'] for m in models['models']]
                print(f"üìã Available models: {', '.join(available_models)}")
                
                if model in available_models:
                    print(f"‚úÖ Model '{model}' is available")
                else:
                    print(f"‚ö†Ô∏è  Model '{model}' not found. Available: {', '.join(available_models)}")
                    print(f"üí° You can pull it with: ollama pull {model}")
            else:
                print("‚ö†Ô∏è  Could not retrieve model list")
        else:
            print(f"‚ùå Ollama service returned status {response.status_code}")
            return False
            
    except requests.exceptions.ConnectionError:
        print("‚ùå Could not connect to Ollama service")
        print("üí° Make sure Ollama is running: ollama serve")
        return False
    except Exception as e:
        print(f"‚ùå Connection test failed: {e}")
        return False
    
    return True

def test_ollama_generation():
    """Test Ollama text generation"""
    print("\nüß™ Testing Ollama Generation...")
    
    ollama_url = os.getenv('OLLAMA_API_URL', 'http://localhost:11434')
    model = os.getenv('OLLAMA_MODEL', 'llama3')
    
    try:
        # Test simple generation
        data = {
            "model": model,
            "prompt": "Say 'Hello from Ollama!' in one sentence.",
            "stream": False,
            "options": {
                "num_predict": 50
            }
        }
        
        response = requests.post(f"{ollama_url}/api/generate", 
                               json=data, 
                               headers={'Content-Type': 'application/json'},
                               timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            if 'response' in result:
                print("‚úÖ Text generation successful")
                print(f"üìù Response: {result['response'].strip()}")
                return True
            else:
                print("‚ùå Unexpected response format")
                print(f"Response: {result}")
                return False
        else:
            print(f"‚ùå Generation failed with status {response.status_code}")
            print(f"Response: {response.text}")
            return False
            
    except Exception as e:
        print(f"‚ùå Generation test failed: {e}")
        return False

def test_python_code_suggestion():
    """Test Python code suggestion functionality"""
    print("\nüß™ Testing Python Code Suggestion...")
    
    ollama_url = os.getenv('OLLAMA_API_URL', 'http://localhost:11434')
    model = os.getenv('OLLAMA_MODEL', 'llama3')
    
    try:
        # Test Python code suggestion
        prompt = """You are a Python programming assistant. Provide a brief suggestion for improving this code:

def calculate_sum(numbers):
    total = 0
    for num in numbers:
        total += num
    return total

Provide one specific improvement suggestion:"""
        
        data = {
            "model": model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.3,
                "num_predict": 100
            }
        }
        
        response = requests.post(f"{ollama_url}/api/generate", 
                               json=data, 
                               headers={'Content-Type': 'application/json'},
                               timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            if 'response' in result:
                print("‚úÖ Python code suggestion successful")
                print(f"üí° Suggestion: {result['response'].strip()}")
                return True
            else:
                print("‚ùå Unexpected response format")
                return False
        else:
            print(f"‚ùå Code suggestion failed with status {response.status_code}")
            return False
            
    except Exception as e:
        print(f"‚ùå Code suggestion test failed: {e}")
        return False

def main():
    """Run all Ollama tests"""
    print("üöÄ Ollama Connection Test")
    print("=" * 40)
    
    tests = [
        test_ollama_connection,
        test_ollama_generation,
        test_python_code_suggestion
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        if test():
            passed += 1
        print()
    
    print("=" * 40)
    print(f"Test Results: {passed}/{total} tests passed")
    
    if passed == total:
        print("üéâ All Ollama tests passed! Your setup is ready.")
        print("\nYou can now run the Python Code Editor:")
        print("  python app.py")
    else:
        print("‚ùå Some tests failed. Please check the errors above.")
        return 1
    
    return 0

if __name__ == "__main__":
    import sys
    sys.exit(main())
